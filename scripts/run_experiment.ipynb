{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import hydra\n",
    "import omegaconf\n",
    "from experiment_util.experiment_data import ExperimentData\n",
    "from experiment_util.plotting import plot_predictions, plot_metrics_for_one_run\n",
    "from experiment_util.eval_single_run import eval_one_model\n",
    "from metalearning_model_gmm_np.mm_gmm_np import MetaLearningModelGMMNP\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE EXPERIMENT HERE ##\n",
    "experiment = \"Sinusoid1D\"\n",
    "# experiment = \"LineSine1D\"\n",
    "\n",
    "## SET TO FALSE FOR FULL RUN ##\n",
    "smoke_test = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load config\n",
    "with hydra.initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "            f\"+experiment={experiment}_64_16\",\n",
    "            f\"+model=GMMNP-{experiment}_64_16\",\n",
    "            f\"do_smoke_test={smoke_test}\",\n",
    "        ],\n",
    "    )\n",
    "cfg = omegaconf.OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True)\n",
    "# pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate model\n",
    "print(\"\\n****** Generating model ******\")\n",
    "model = MetaLearningModelGMMNP(\n",
    "    cfg=cfg[\"model\"],\n",
    "    d_x=cfg[\"experiment\"][\"d_x\"],\n",
    "    d_y=cfg[\"experiment\"][\"d_y\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate data\n",
    "print(\"\\n****** Generating data ******\")\n",
    "exp_data = ExperimentData(cfg[\"experiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## meta train\n",
    "print(\"\\n****** Meta-Training ******\")\n",
    "model.meta_train(\n",
    "    benchmark=exp_data.benchmark_meta_train,\n",
    "    n_epochs=cfg[\"model\"].get(\"n_epochs_meta_train\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot some predictions on test benchmark\n",
    "print(\"\\n****** Plotting on test set ******\")\n",
    "figs = plot_predictions(\n",
    "    model=model,\n",
    "    benchmark=exp_data.benchmark_test,\n",
    "    task_ids=cfg[\"experiment\"][\"task_ids_plot\"],\n",
    "    context_sizes=cfg[\"experiment\"][\"context_sizes_plot\"],\n",
    "    n_samples=cfg[\"experiment\"][\"n_samples_plot\"],\n",
    "    n_epochs_adapt=cfg[\"model\"].get(\"n_epochs_adapt\", None),\n",
    "    plot_std_y=cfg[\"experiment\"][\"plot_std_y\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate model on test benchmark\n",
    "print(\"\\n****** Evaluating on test set ******\")\n",
    "test_metrics = eval_one_model(\n",
    "    benchmark=exp_data.benchmark_test,\n",
    "    model=model,\n",
    "    context_sizes=cfg[\"experiment\"][\"context_sizes_eval\"],\n",
    "    n_samples=cfg[\"experiment\"][\"n_samples_eval\"],\n",
    "    context_size_proposal=cfg[\"experiment\"][\"context_size_proposal_test\"],\n",
    "    n_epochs_adapt=cfg[\"model\"].get(\"n_epochs_adapt\", None),\n",
    "    batch_size_eval=cfg[\"experiment\"][\"batch_size_eval\"],\n",
    ")\n",
    "plot_metrics_for_one_run(\n",
    "    metrics=test_metrics,\n",
    "    kind=\"line\",\n",
    "    task_aggregate_op=cfg[\"experiment\"][\"metrics_reduce_mode\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('iclr2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75811d3751077f02277cf20ded9c02c21894cb77a29d19a4c9366399cad47331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
